{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6926857-4723-4260-b780-ef18068e5ab7",
   "metadata": {},
   "source": [
    "# snippy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eaeff66-b508-4242-8d7c-9525d09ef907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from Bio import *\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import traceback\n",
    "from adjustText import adjust_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1da06742-0f34-4850-a9d4-e1b680897744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vcf_file(filepath): \n",
    "    with open(filepath + '/' + 'snps_new.csv', 'w') as f:\n",
    "        f.write('')\n",
    "    with open(filepath + '/' + 'snps.vcf', 'r') as f:\n",
    "        for line in f: \n",
    "            if line[0] != '#':\n",
    "                with open(filepath + '/' + 'snps_new.csv', 'a') as f:\n",
    "                    f.write(line)  \n",
    "    columns = ['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAl', 'FILTER', 'INFO', 'FORMAT', \"filename\"]              \n",
    "    df = pd.read_csv(filepath + '/'+ 'snps_new.csv', sep = '\\t', names = columns)\n",
    "    df = df.drop(['INFO', 'FORMAT', 'filename', 'FILTER'], axis = 1)\n",
    "    df.to_csv(filepath + '/' + 'snps_new.csv', index = False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d51ee7b-5a83-453e-aca6-064799409c0a",
   "metadata": {},
   "source": [
    "## read in the snps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f16f2692-0339-44b8-991f-d45b55577533",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_df = pd.read_csv(r'C:\\Users\\Halewijn\\OneDrive\\Documenten\\third year\\BEP\\thesis\\anti defence gene bioinformatics\\ID' + '/' + 'ID.csv', dtype={'ID':'str'})\n",
    "ID_df = ID_df.dropna()\n",
    "ID_df.columns = ['Job', 'Owner', \"ID\", \"phage\", \"Num contigs\", \"Size (bp)\"]\n",
    "ID_df = ID_df.reindex(['ID', 'Size (bp)', 'phage'], axis =1)\n",
    "ID_df.loc[:, 'phage'] = list(ID_df.loc[:, 'phage'].str.extract('(?<=FB)(.*)').loc[:, 0])\n",
    "ID_df.loc[:, 'ID'] = ID_df.loc[:, 'ID'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0902b5e5-2a47-4c0a-8ada-80ffd5734c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints all the folders\n",
    "morphology_df = pd.read_csv(\"C:/Users/Halewijn/OneDrive/Documenten/third year/BEP/thesis/morphology data\" + \"/condensed morphology data.csv\")\n",
    "filelist = os.listdir(r'C:\\Users\\Halewijn\\OneDrive\\Documenten\\third year\\BEP\\thesis\\mutational analysis\\input_snippy_data')\n",
    "folders_list = []\n",
    "for filename in filelist:\n",
    "    if(filename.endswith('inter') or filename.endswith('intra')):\n",
    "         folders_list = folders_list + [filename]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7971044e-9ba6-410f-b796-e7e7df53ec9b",
   "metadata": {},
   "source": [
    "Here, we extract information out of the foldernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed09fcc0-1664-4faf-acea-6e62aa13efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "extr_information = pd.Series(folders_list).str.extract(\"(?<=myo_)(.*)\").replace(np.NaN, '') + pd.Series(folders_list).str.extract(\"(?<=podo_)(.*)\").replace(np.NaN, '')\n",
    "extr_information = extr_information.rename({0: 'inter or intra + number'}, axis = 1)\n",
    "extr_information.loc[:, 'family'] = extr_information.loc[:, 'inter or intra + number'].str.extract(\"(.*?)(?=_i)\").replace(np.NaN, 0)\n",
    "extr_information.loc[:, 'inter or intra'] =extr_information.loc[:, 'inter or intra + number'].str.extract(\"(?=i)(.*)\").replace(np.NaN, 0)\n",
    "extr_information = extr_information.drop('inter or intra + number', axis = 1)\n",
    "extr_information.loc[:, 'reference'] = pd.Series(folders_list).str.extract(\"(Pa.*[0-9].r)\")\n",
    "extr_information.loc[:, 'reference'] = extr_information.loc[:, 'reference'].str[:-1]\n",
    "indexes = extr_information.loc[:, 'reference'].str[-1] == '_'\n",
    "extr_information.loc[indexes, 'reference'] = extr_information.loc[:, 'reference'].str[0:-1]\n",
    "extr_information.loc[:,'reads'] = pd.Series(folders_list).str.extract(\"(?<=reads)(.*?)(?=m|p|s)\")\n",
    "extr_information.loc[:, 'reads'] =  extr_information.loc[:, 'reads'].str.replace('_', '')\n",
    "extr_information.loc[:, 'foldername'] = pd.Series(folders_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec7f73e-dc8c-4c2b-a048-f64813826d61",
   "metadata": {},
   "source": [
    "Here, we extract the snps.raw and paste the information from previously in the dataframe. At the end, the dataframes are concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ff2a697-9a67-4069-b59a-4eb739b6a1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = []\n",
    "zero_reads_array = []\n",
    "zero_reference_array = []\n",
    "for ii in range(extr_information.shape[0]):\n",
    "    filepath = r'C:\\Users\\Halewijn\\OneDrive\\Documenten\\third year\\BEP\\thesis\\mutational analysis\\input_snippy_data' + '/' + str(extr_information.loc[ii, 'foldername'])\n",
    "    try: \n",
    "        read_vcf_file(filepath)\n",
    "        df = pd.read_csv(filepath + '/' + 'snps_new.csv')\n",
    "        df.loc[:, 'family'] = [extr_information.loc[ii, 'family']]*df.shape[0]\n",
    "        df.loc[:, 'inter or intra'] = [extr_information.loc[ii, 'inter or intra']]*df.shape[0]\n",
    "        df.loc[:, 'reference'] = [extr_information.loc[ii, 'reference']]*df.shape[0]\n",
    "        df.loc[:, 'reads'] = [extr_information.loc[ii, 'reads']]*df.shape[0]\n",
    "        big_df = big_df + [df]\n",
    "        if df.shape[0] == 0: \n",
    "            continue\n",
    "            # print(extr_information.loc[ii, 'reference'])\n",
    "            # print(extr_information.loc[ii, 'reads'])\n",
    "\n",
    "    except: \n",
    "        print(str(extr_information.loc[ii, 'foldername']))\n",
    "big_big_df = pd.concat(big_df)\n",
    "#because the position is different if we're replacing the bases later\n",
    "big_big_df.loc[:, 'POS'] = big_big_df.loc[:, 'POS'] -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97af54cf-4c7d-4f4e-9dda-e0c7578532c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_snps_df = big_big_df[['reads', 'reference']].groupby(['reads', 'reference'], as_index = False).size().pivot_table(index = 'reads', columns = 'reference', values = 'size').fillna(0).stack().reset_index().rename({0: 'count'}, axis = 1)\n",
    "filt_no_snps_df = num_snps_df[num_snps_df.loc[:, 'count'] < 2]\n",
    "filt_no_snps_df[filt_no_snps_df.loc[:, 'reads'] != filt_no_snps_df.loc[:, 'reference']]\n",
    "\n",
    "#phage sizes \n",
    "genome_size = pd.read_csv('final_phage_genome_size.csv')\n",
    "\n",
    "filt_no_snps_df = pd.merge(pd.merge(filt_no_snps_df, genome_size, left_on = 'reference', right_on='Phages').drop('Phages', axis = 1).rename({'Genome size (bp)': 'Size reference'}, axis = 1), genome_size, left_on = 'reads', right_on= 'Phages').drop('Phages', axis = 1).rename({'Genome size (bp)': 'Size reads'}, axis = 1)\n",
    "#pd.merge(filt_no_snps_df, ID_df[['phage', 'Size (bp)']], left_on='reference', right_on = 'phage', copy= False)\n",
    "filt_filt_no_snps_df =  filt_no_snps_df[filt_no_snps_df.loc[:, 'reads'] != filt_no_snps_df.loc[:, 'reference']]\n",
    "filt_filt_no_snps_df.loc[:, 'size difference'] = filt_filt_no_snps_df.loc[:, 'Size reference'] - filt_filt_no_snps_df.loc[:, 'Size reads']\n",
    "filt_filt_no_snps_df.to_csv('checkout.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "977f7d1a-dc65-4b22-b463-f93364111671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.clustermap(big_big_df.groupby(['reference', 'reads'], as_index = False).size().pivot_table(index = 'reads', columns='reference', values='size').fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e461b8b-978a-4b56-abab-0e0e6123214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_of_snps = big_big_df.groupby(['reference', 'reads'], as_index = False).size().sort_values('size', ascending = True)\n",
    "amount_of_snps = pd.merge(amount_of_snps, morphology_df, left_on = 'reference', right_on='phage').rename({'morphology': 'morphology reference'}, axis = 1)\n",
    "amount_of_snps = pd.merge(amount_of_snps, morphology_df, left_on = 'reads', right_on = 'phage').rename({'morphology': 'morphology reads'}, axis = 1)\n",
    "#amount_of_snps[(amount_of_snps.loc[:, 'morphology reads'] == 'Myoviridae') & (amount_of_snps.loc[:, 'morphology reference'] == 'Myovirdae')]\n",
    "a = amount_of_snps[(amount_of_snps.loc[:, 'morphology reads'] == 'Myoviridae') & (amount_of_snps.loc[:, 'morphology reference'] == 'Myoviridae')].sort_values('size').head(60)\n",
    "\n",
    "#amount_of_snps.sort_values('size', ascending = True).head(50)\n",
    "# amount_of_snps[amount_of_snps.loc[:, 'reads'] == 'Pa29']\n",
    "# amount_of_snps.loc[:, 'reference'].unique()\n",
    "# amount_of_snps[()]\n",
    "#amount_of_snps[(amount_of_snps.loc[:, 'morphology reads'] == 'Myoviridae') & (amount_of_snps.loc[:, 'morphology reference'] == 'Myoviridae')].sort_values('size').head(60)\n",
    "#a.loc[:, 'reads'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64a1bab4-30cb-444f-ba29-b8d5b71c02b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0274618357223115"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_intra_inter = big_big_df.groupby('inter or intra', as_index = False).count().loc[:, 'reads']\n",
    "percentage_intra = (size_intra_inter[1]/size_intra_inter[0])*100\n",
    "percentage_intra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba1d7bd-8201-4902-86ed-7f6b7cc68774",
   "metadata": {},
   "source": [
    "## Add the morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4cee96-25b7-4eba-a4e6-8478ae48a181",
   "metadata": {},
   "source": [
    "add the morphology to the snp dataframe. From the reference, but also from the reads. The dataframe is saved as morph_big_big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3757fa7e-a90b-4f56-84b9-77c3810bede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_big_big_df = pd.merge(big_big_df, morphology_df,left_on='reference', right_on = 'phage')\n",
    "morph_big_big_df = morph_big_big_df[['POS', 'REF', 'ALT', 'reference', 'reads', 'morphology']].rename({'morphology': 'morphology reference'}, axis = 1)\n",
    "morph_big_big_df = pd.merge(morph_big_big_df, morphology_df,left_on='reads', right_on = 'phage').rename({'morphology': 'morphology reads'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "522d8649-85ad-41c2-8fc4-a7a89aec2f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_big_big_df.to_csv('morph_big_big_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a20b8e-e7e9-4e5e-81c3-9b47078d042b",
   "metadata": {},
   "source": [
    "## Add the ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd2266c-9b3a-4c26-a2c4-5568043f826f",
   "metadata": {},
   "source": [
    "Here, we get the positions of each SNP, and also the ID of the gbk file. The dataframe is saves as ID_morph_big_big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df94437b-d5c0-4e7c-b56f-794cb71ab08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#secondly, import the ID df, because the all_snippy_dataframe does not have the phage ID with it. make sure to merge at the end with the latest ID\n",
    "ID_df = pd.read_csv(r'C:\\Users\\Halewijn\\OneDrive\\Documenten\\third year\\BEP\\thesis\\anti defence gene bioinformatics\\ID' + '/' + 'ID.csv', dtype={'ID':'str'})\n",
    "ID_df = ID_df.dropna()\n",
    "ID_df.columns = ['Job', 'Owner', \"ID\", \"phage\", \"Num contigs\", \"Size (bp)\"]\n",
    "ID_df = ID_df.reindex(['ID', 'Size (bp)', 'phage'], axis =1)\n",
    "ID_df.loc[:, 'phage'] = list(ID_df.loc[:, 'phage'].str.extract('(?<=FB)(.*)').loc[:, 0])\n",
    "ID_df.loc[:, 'ID'] = ID_df.loc[:, 'ID'].astype('str')\n",
    "\n",
    "#merge them\n",
    "ID_morph_big_big_df = pd.merge(morph_big_big_df, ID_df[['ID', 'phage']], left_on='reference', right_on = 'phage').rename({'ID':'ID of reference'}, axis = 1).drop(['phage_x', 'phage_y'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a912c618-5a50-418b-8721-54757d782620",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_morph_big_big_df.to_csv('ID_morph_big_big_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b3e902-91dd-4d2a-a768-c9eafac65af9",
   "metadata": {},
   "source": [
    "## import the genic regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa73643c-a92b-4279-851e-e1a592d3f562",
   "metadata": {},
   "source": [
    "All the gene regions, with their respective annotations are make here and saved as big_intergenic_df.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "918c7149-6651-4e5b-9f20-e95bb73ce997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#first, make the genic dataframe\n",
    "big_intergenic_df = []\n",
    "phage_gbks_filepath = r'C:\\Users\\Halewijn\\OneDrive\\Documenten\\third year\\BEP\\thesis\\mutational analysis\\intergenic regions\\phage gbk'\n",
    "phage_gbks_filenames = os.listdir(phage_gbks_filepath)\n",
    "for phage_gbk_filename in phage_gbks_filenames: \n",
    "    dictionary = {'gene start': [], 'gene stop': [], 'complement': [], 'protein translation': [], 'protein annotation': [], 'product': []}\n",
    "    for seq_record in SeqIO.parse(phage_gbks_filepath + '/' + phage_gbk_filename, 'genbank'): \n",
    "        for seq_feature in seq_record.features:\n",
    "            if seq_feature.type == 'CDS': \n",
    "                start = seq_feature.location.start\n",
    "                stop = seq_feature.location.end\n",
    "                complement = seq_feature.location.strand\n",
    "                translation = seq_feature.qualifiers['translation']\n",
    "                annotation = seq_feature.qualifiers['db_xref']\n",
    "                product = seq_feature.qualifiers['product']\n",
    "                dictionary['gene start'].append(int(start))\n",
    "                dictionary['gene stop'].append(int(stop))\n",
    "                dictionary['complement'].append(complement)\n",
    "                dictionary['protein translation'].append(translation)\n",
    "                dictionary['protein annotation'].append(annotation)\n",
    "                dictionary['product'].append(product)\n",
    "    intergenic_df = pd.DataFrame(dictionary)\n",
    "    intergenic_df.loc[:, 'ID'] = [phage_gbk_filename[:-4]]*intergenic_df.shape[0]\n",
    "    big_intergenic_df = big_intergenic_df + [intergenic_df]  \n",
    "    \n",
    "big_intergenic_df = pd.concat(big_intergenic_df, ignore_index=True)\n",
    "\n",
    "#also merge it with the morphology df\n",
    "big_intergenic_df = pd.merge(big_intergenic_df, ID_df[['ID', 'phage']])\n",
    "big_intergenic_df.to_csv('big_intergenic_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69474b20-f4ad-43a6-9c9c-a419c41732ac",
   "metadata": {},
   "source": [
    "## Find where each snp belongs to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9a4cc9-643f-41ab-aeea-0ba924e2770b",
   "metadata": {},
   "source": [
    "This code takes a while to run. Here, we go over each snp position for a certain reference. If its find a hit, it gets saved, together with the annotation etc. The dataframes is later concatenated and saved as snp_in_gene_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32a2daee-7b46-47e2-91d2-ef446c3dfe26",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pa10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Halewijn\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pa14\n",
      "Pa21\n",
      "Pa24\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'position'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item_mgr\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3750\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3751\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3752\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'position'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_664/2135858434.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mreads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mref_snp_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reads'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mhit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mref_genic_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mref_genic_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gene start'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mref_genic_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gene stop'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mhit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mhit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mhit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reads'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mreads\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mhit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m#hit.loc[:, 'complement'] = [complement]*hit.shape[0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m         \u001b[0miloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"iloc\"\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 723\u001b[1;33m         \u001b[0miloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    724\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1665\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_null_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1666\u001b[0m                             \u001b[1;31m# We are setting an entire column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1667\u001b[1;33m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1668\u001b[0m                             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1669\u001b[0m                         \u001b[1;32melif\u001b[0m \u001b[0mis_array_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3610\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3611\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3612\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3614\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3795\u001b[0m                     \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexisting_piece\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3797\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3799\u001b[0m     def _set_value(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item_mgr\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3752\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3753\u001b[0m             \u001b[1;31m# This item wasn't present, just insert at end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3754\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3755\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3756\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iset_item_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36minsert\u001b[1;34m(self, loc, item, value)\u001b[0m\n\u001b[0;32m   1162\u001b[0m         \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1164\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mblkno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_fast_count_smallints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1165\u001b[0m             \u001b[0mblk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mblkno\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mblknos\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[1;31m# Note: these can be altered by other BlockManager methods.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rebuild_blknos_and_blklocs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_rebuild_blknos_and_blklocs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[0mnew_blknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblkno\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m             \u001b[0mnew_blklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnew_blknos\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "references = ID_morph_big_big_df.loc[:, 'reference'].unique()\n",
    "all_hits = []\n",
    "for i in range(len(references)): \n",
    "    reference = references[i]\n",
    "    print(reference)\n",
    "    ref_snp_df = ID_morph_big_big_df[ID_morph_big_big_df.loc[:, 'reference'] == reference][['POS', 'reads']].reset_index(drop = True)\n",
    "    ref_genic_df = big_intergenic_df[big_intergenic_df.loc[:, 'phage'] == reference][['gene start', 'gene stop' , 'protein annotation', 'product', 'complement', 'protein translation']].reset_index(drop = True)\n",
    "    snp_length = ref_snp_df.shape[0]\n",
    "    genic_length = ref_genic_df.shape[0]\n",
    "    for ii in range(snp_length): \n",
    "        position = ref_snp_df.loc[ii, 'POS']\n",
    "        reads = ref_snp_df.loc[ii, 'reads']\n",
    "        hit = ref_genic_df[((ref_genic_df.loc[:, 'gene start'] <= position) & (ref_genic_df.loc[:, 'gene stop'] >= position))]\n",
    "        hit.loc[:, 'position'] = [position]*hit.shape[0]\n",
    "        hit.loc[:, 'reads'] = [reads]*hit.shape[0]\n",
    "        #hit.loc[:, 'complement'] = [complement]*hit.shape[0]\n",
    "        \n",
    "        hit.loc[:, 'reference'] = [reference]*hit.shape[0]\n",
    "        all_hits = all_hits + [pd.DataFrame(hit)]\n",
    "    # big_hit = pd.concat(big_hit, ignore_index=True)\n",
    "    # big_hit.loc[:, 'phage'] = [reference]*big_hit.shape[0]\n",
    "    # big_big_hit = big_big_hit + [big_hit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba2dbab-3e1a-48a8-9b27-621fa0278d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_gene_translation = pd.concat(all_hits)\n",
    "snp_in_gene_df = pd.merge(ID_morph_big_big_df, pos_gene_translation, left_on = ['POS', 'reference', 'reads'], right_on=['position', 'reference', 'reads']).drop(['position'], axis = 1)\n",
    "snp_in_gene_df.to_csv('snp_in_gene_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef16fc-8986-41e8-b4aa-fbf5f3df3c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_gene_translation = pd.concat(big_big_hit, ignore_index=True)\n",
    "# pos_gene_translation = pd.merge(ID_morph_big_big_df, pos_gene_translation[['protein translation', 'position', 'phage', 'reads', 'gene start', 'gene stop', 'complement']], left_on = ['POS', 'reference', 'reads'], right_on=['position', 'phage', 'reads'])\n",
    "# pos_gene_translation =  pos_gene_translation[['POS', 'REF', 'gene start', 'gene stop','ALT', 'reference', 'reads', 'morphology reference', 'morphology reads', 'ID of reference', 'protein translation', 'complement']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e68de8-eea4-447a-b57c-8f3ae1e6833e",
   "metadata": {},
   "source": [
    "## filter step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc2a443-d187-49d4-ae9e-75ea50ee05c3",
   "metadata": {},
   "source": [
    "filter on morphology, the fact that we can only have 1 snp, and that the protein has to start with M. The dataframe is saved as filtered_snp_df.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0cdf6bf8-fbe3-42bd-b055-76479d9dd33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Halewijn\\AppData\\Local\\Temp/ipykernel_664/4060901585.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  filtered_snp_df = filtered_snp_df[snp_in_gene_df.loc[:,'protein translation'].astype('str').str[2] == 'M']\n"
     ]
    }
   ],
   "source": [
    "snp_in_gene_df = pd.read_csv('snp_in_gene_df.csv')\n",
    "filtered_snp_df = snp_in_gene_df[(snp_in_gene_df.loc[:, 'REF'].str.len() == 1) & (snp_in_gene_df.loc[:, 'morphology reference'] == 'Myoviridae')\n",
    "                                & (snp_in_gene_df.loc[:, 'morphology reads'] == 'Myoviridae')].reset_index(drop = True)\n",
    "filtered_snp_df = filtered_snp_df[snp_in_gene_df.loc[:,'protein translation'].astype('str').str[2] == 'M']\n",
    "filtered_snp_df =  pd.merge(filtered_snp_df.drop('ID of reference', axis =1 ), ID_df, left_on='reference', right_on='phage')\n",
    "filtered_snp_df.to_csv('filtered_snp_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755140e9-1cf8-40ac-9182-31e42f697c83",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get the DNA sequence, next to each row, and make the mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d972fec-d71d-47ce-ae68-04c5068a0bd9",
   "metadata": {},
   "source": [
    "Here, we go to one of the last steps, in which the adaptation is made to the protein. Be carefull here: the adaption is made on the read sequence, not on the reference sequence. This code takes a while to run. It is eventually saved in two arrays: the error array and the alt_protein array. The result is a dataframe with all mutations, their effect on the protein and the exceptions if there are. The dataframe is saved as: final_df.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612fab7b-0bb6-4d37-b7b9-7cb578cf4e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_snp_df = pd.read_csv('filtered_snp_df.csv', dtype={'ID':'str'})\n",
    "filtered_snp_df.loc[:, 'ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aa5087-8c2c-4652-92bf-143a0db6e6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "synonymous = []\n",
    "synonymous_array = []\n",
    "error_array = []\n",
    "alt_protein_array = []\n",
    "alt_sequence_array = []\n",
    "error_dictionary = {}\n",
    "#for ii in range(filtered_snp_df.shape[0]): \n",
    "i = 0\n",
    "for ii in range(filtered_snp_df.shape[0]):\n",
    "    i = i + 1 \n",
    "    if i == 10000: \n",
    "        print(str(i))\n",
    "        i = 0\n",
    "    row = ii\n",
    "    phage_genbank_filepath = r'C:\\Users\\Halewijn\\OneDrive\\Documenten\\third year\\BEP\\thesis\\mutational analysis\\intergenic regions\\phage gbk'\n",
    "    gene_start = filtered_snp_df.loc[row, 'gene start']\n",
    "    gene_stop = filtered_snp_df.loc[row, 'gene stop']\n",
    "    ID = filtered_snp_df.loc[row, 'ID']\n",
    "    REF = filtered_snp_df.loc[row, 'REF']\n",
    "    POS = filtered_snp_df.loc[row, 'POS']\n",
    "    ALT = filtered_snp_df.loc[row, 'ALT']\n",
    "    complement = filtered_snp_df.loc[row, 'complement']\n",
    "    original_protein = filtered_snp_df.loc[row, 'protein translation'][0]\n",
    "    for seq_record in SeqIO.parse(phage_genbank_filepath + '/' + ID + '.gbk', 'genbank'): \n",
    "        sequence = seq_record.seq\n",
    "        gene = sequence[gene_start:gene_stop]\n",
    "        pos_relative_to_gene = POS - gene_start\n",
    "        alt_gene = gene[:pos_relative_to_gene] + ALT + gene[pos_relative_to_gene+1:]\n",
    "        if complement == -1: \n",
    "            alt_gene = alt_gene.reverse_complement()\n",
    "        error = False\n",
    "        try: \n",
    "            alt_protein = alt_gene.translate(cds = True)\n",
    "        except Exception as x: \n",
    "            error = x\n",
    "            alt_protein = alt_gene.translate(cds = False)\n",
    "        error_array = error_array + [error]\n",
    "        alt_sequence_array = alt_sequence_array + [alt_gene]\n",
    "        alt_protein_array = alt_protein_array + [alt_protein]\n",
    "        #alt_protein_array = alt_protein_array + [alt_protein]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea928a62-d1b7-4181-afde-ece3a7e669ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_snp_df.loc[:,'altered sequence'] = alt_sequence_array\n",
    "filtered_snp_df.loc[:, 'error'] = error_array\n",
    "filtered_snp_df.loc[:, 'altered protein'] = alt_protein_array\n",
    "filtered_snp_df.to_csv('final_df.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b040581b-facf-4c21-b46f-bbd6a83c8bd9",
   "metadata": {},
   "source": [
    "## This time, include the fact that multiple mutations occur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89071495-1b9b-4eda-b4b0-00c405557761",
   "metadata": {},
   "source": [
    "Is there the need to combine all the mutations? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6e8267-8ee6-4173-a53f-29b2c08796ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_snp = pd.read_csv('filtered_snp_df.csv', dtype={'ID':'str'}).drop('Unnamed: 0', axis = 1)\n",
    "filtered_df_snp.loc[:, 'size protein'] = filtered_df_snp.loc[:, 'protein translation'].str[2:-2].str.len()\n",
    "#sns.histplot(data = filtered_df_snp.groupby(['protein annotation'],as_index = False).size(), x = 'size')\n",
    "#filtered_df_snp.groupby(['protein annotation'],as_index = False)[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b959bc4-2601-42c5-a6f9-f12a23e71ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_df_snp.groupby(['protein annotation'], as_index = False)\n",
    "num_mutations_vs_size_df = filtered_df_snp.groupby(['protein annotation'], as_index = False)['size protein'].mean()\n",
    "num_mutations_vs_size_df.loc[:, 'num mutations'] =  filtered_df_snp.groupby(['protein annotation'], as_index = False).size().loc[:, 'size']\n",
    "num_mutations_vs_size_df.loc[:, 'ratio'] = num_mutations_vs_size_df.loc[:, 'size protein']/num_mutations_vs_size_df.loc[:, 'num mutations']\n",
    "num_mutations_vs_size_df.loc[:, 'product'] = filtered_df_snp.groupby('protein annotation', as_index = False)['product'].agg(pd.Series.mode).loc[:, 'product']\n",
    "\n",
    "#find out the relation between mutations in polymerase and mutations in the rest of the genome\n",
    "DNA_polymerase_df = filtered_df_snp[(filtered_df_snp.loc[:, 'product'] == \"['DNA polymerase III alpha subunit (EC 2.7.7.7)']\") \n",
    "                                   ]\n",
    "gr_DNA_polymerase_df = DNA_polymerase_df.groupby('protein annotation', as_index = False).size().rename({\"size\": 'mutations in polymerase'}, axis = 1)\n",
    "gr_DNA_polymerase_df.loc[:, 'ID'] = DNA_polymerase_df.groupby('protein annotation', as_index = False)['ID'].agg(pd.Series.mode).loc[:, 'ID']\n",
    "gr_DNA_polymerase_df.loc[:, 'tot mutations'] = filtered_df_snp.groupby('ID', as_index = False)['ID'].size().loc[:, 'size']\n",
    "gr_DNA_polymerase_df.loc[:, 'mutations except DNA pol'] = gr_DNA_polymerase_df.loc[:, 'tot mutations'] - gr_DNA_polymerase_df.loc[:, 'mutations in polymerase']\n",
    "gr_DNA_polymerase_df = pd.merge(gr_DNA_polymerase_df, ID_df[['phage', 'ID']])\n",
    "#scatterplot\n",
    "x = gr_DNA_polymerase_df.loc[:, 'mutations in polymerase']\n",
    "y = gr_DNA_polymerase_df.loc[:, 'mutations except DNA pol']\n",
    "labels = gr_DNA_polymerase_df.loc[:, 'phage']\n",
    "\n",
    "fig, axes = plt.subplots(2,3, figsize = (10,7))\n",
    "sns.histplot(data = num_mutations_vs_size_df, x ='num mutations', ax = axes[0][0])\n",
    "sns.histplot(data = num_mutations_vs_size_df, x='num mutations', y = 'size protein', ax = axes[0][1])\n",
    "sns.regplot(data = num_mutations_vs_size_df, x = 'num mutations', y='size protein', ax = axes[0][2], scatter_kws={'s':0.5}, ci = False)\n",
    "sns.histplot(data = num_mutations_vs_size_df[num_mutations_vs_size_df.loc[:, 'ratio'] < 1.5], x = 'ratio', bins = 50, ax = axes[1][0])\n",
    "sns.regplot(data = gr_DNA_polymerase_df, x = 'mutations in polymerase', y = 'mutations except DNA pol', ax = axes[1][1], ci = False, scatter_kws={'s':5})\n",
    "sns.scatterplot(x=x, y=y, ax = axes[1][2])\n",
    "texts = [plt.text(x_pos, y_pos, f'{l}') for (x_pos, y_pos, l) in zip(x, y, labels)]\n",
    "adjust_text(texts)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f245246b-24d2-4794-84ac-30a5f0c5a84b",
   "metadata": {},
   "source": [
    "So yes, there is a need for this. What we can also see is that the amount of mutations does not perfectly scale linearly with the size of the protein. Which I think is funny. What is the regression coefficient? The slope is almost 1. In the beginning however, the slope is steeper. Indicating that for small proteins, you actually have a lot of mutations. The last plot is maybe not so right after all. The sum of mutations namely really depends on what phages you compare to each other, so maybe I need to filter on that. So to just take a phage as reference, assuming this one has no mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03685aa-4993-4873-afb0-5f00dbe6e6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNA_polymerase_df = filtered_df_snp[(filtered_df_snp.loc[:, 'product'] == \"['DNA polymerase III alpha subunit (EC 2.7.7.7)']\")]\n",
    "#DNA_polymerase_df.groupby('reads', as_index = False).size().sort_values('size')\n",
    "# gr_DNA_polymerase_df = DNA_polymerase_df.groupby('protein annotation', as_index = False).size().rename({\"size\": 'mutations in polymerase'}, axis = 1)\n",
    "# gr_DNA_polymerase_df.loc[:, 'ID'] = DNA_polymerase_df.groupby('protein annotation', as_index = False)['ID'].agg(pd.Series.mode).loc[:, 'ID']\n",
    "# gr_DNA_polymerase_df.loc[:, 'tot mutations'] = filtered_df_snp.groupby('ID', as_index = False)['ID'].size().loc[:, 'size']\n",
    "# gr_DNA_polymerase_df.loc[:, 'mutations except DNA pol'] = gr_DNA_polymerase_df.loc[:, 'tot mutations'] - gr_DNA_polymerase_df.loc[:, 'mutations in polymerase']\n",
    "# gr_DNA_polymerase_df = pd.merge(gr_DNA_polymerase_df, ID_df[['phage', 'ID']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f62a6-805b-452a-8615-4a970f0e6fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_phages= DNA_polymerase_df.loc[:, 'reference'].unique()\n",
    "df_array = []\n",
    "for ii in range(len(reference_phages)): \n",
    "    reference = reference_phages[ii]\n",
    "    ref_DNA_polymerase_df = DNA_polymerase_df[DNA_polymerase_df.loc[:, 'reference'] == reference]\n",
    "    gr_ref_DNA_polymerase_df = ref_DNA_polymerase_df.groupby('reads').size().reset_index()\n",
    "    gr_ref_DNA_polymerase_df.loc[:, 'reference'] = [reference]*gr_ref_DNA_polymerase_df.shape[0]\n",
    "    df_array = df_array + [gr_ref_DNA_polymerase_df]\n",
    "heatmap_df = pd.concat(df_array)\n",
    "sns.heatmap(heatmap_df.pivot_table(index = 'reads', columns='reference', values=0).fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c1c0ea-b177-4f5d-96ef-83f28615524e",
   "metadata": {},
   "source": [
    "make the algorithm to induce the multiple mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb7b752-1cc6-4613-bcfc-9cefa5ad9758",
   "metadata": {},
   "source": [
    "## this is for another section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813d52c9-9451-47a6-a13a-9fb55ceec109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this kernel, I want to find out where exactly the stop codon is. Is it in the middle, or more at the end?\n",
    "wrong_start_stop_df = [filtered_snp_df.loc[:, 'error'] !='False']\n",
    "wrong_start_df = wrong_start_stop_df[wrong_start_stop_df.loc[:, 'error'].str.contains('is not a start codon')].reset_index(drop = True)\n",
    "# wrong_start_df\n",
    "#wrong_start_df.groupby('error', as_index = False).count().sort_values('POS', ascending = False)\n",
    "\n",
    "alt_protein_array = []\n",
    "#for ii in range(wrong_start_df.shape[0]): \n",
    "i = 0\n",
    "for ii in range(wrong_start_df.shape[0]):\n",
    "    i = i + 1 \n",
    "    if i == 10000: \n",
    "        print(str(i))\n",
    "        i = 0\n",
    "    row = ii\n",
    "    phage_genbank_filepath = r'C:\\Users\\Halewijn\\OneDrive\\Documenten\\third year\\BEP\\thesis\\mutational analysis\\intergenic regions\\phage gbk'\n",
    "    gene_start = wrong_start_df.loc[row, 'gene start']\n",
    "    gene_stop = wrong_start_df.loc[row, 'gene stop']\n",
    "    ID = wrong_start_df.loc[row, 'ID']\n",
    "    REF = wrong_start_df.loc[row, 'REF']\n",
    "    POS = wrong_start_df.loc[row, 'POS']\n",
    "    ALT = wrong_start_df.loc[row, 'ALT']\n",
    "    complement = wrong_start_df.loc[row, 'complement']\n",
    "    original_protein = wrong_start_df.loc[row, 'protein translation'][0]\n",
    "    for seq_record in SeqIO.parse(phage_genbank_filepath + '/' + ID + '.gbk', 'genbank'): \n",
    "        a = 1\n",
    "        \n",
    "        sequence = seq_record.seq\n",
    "        gene = sequence[gene_start:gene_stop]\n",
    "        pos_relative_to_gene = POS - gene_start\n",
    "        alt_gene = gene[:pos_relative_to_gene] + ALT + gene[pos_relative_to_gene+1:]\n",
    "        if complement == -1: \n",
    "            alt_gene = alt_gene.reverse_complement()\n",
    "        alt_protein = alt_gene.translate()\n",
    "        alt_protein_array = alt_protein_array + [alt_protein]\n",
    "        # error = False\n",
    "        # try: \n",
    "        #     alt_protein = alt_gene.translate(cds = True)\n",
    "        # except Exception as x: \n",
    "        #     error = x\n",
    "        # error_array = error_array + [error]\n",
    "        # synonymous_array = synonymous_array + [alt_protein]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95620fe-4375-4aee-9f7b-7e3716f4a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrong_start_df.loc[:, 'altered protein'] = alt_protein_array\n",
    "# wrong_start_df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e7e0c3-1a21-47c0-8b0a-bea82f23997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_start_df.loc[:, 'length of original gene'] = wrong_start_df.loc[:, 'altered protein'].str.len()\n",
    "wrong_start_df.loc[:, 'new start pos'] = wrong_start_df.loc[:, 'altered protein'].astype('str').str.find('M')\n",
    "wrong_start_df.loc[:, 'percentage of gene cut off'] = wrong_start_df.loc[:, 'new start pos']/wrong_start_df.loc[:, 'length of original gene']*100\n",
    "wrong_start_df = wrong_start_df.drop(['length of original gene', 'new start pos'], axis = 1)\n",
    "wrong_start_df.to_csv('wrong_start_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4897d8c0-e30e-4917-ab9a-8bff37a8f51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(synonymous)\n",
    "a.loc[:, 'equals false'] = (a.loc[:, 0] == False)\n",
    "a[a.loc[:, 'equals false'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b36eb-a51f-472b-a110-2745fa0fafd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene == alt_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702d670f-c393-473c-ab29-b38fd3af8054",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq_record in SeqIO.parse(r'C:\\Users\\Halewijn\\OneDrive\\Documenten\\third year\\BEP\\thesis\\mutational analysis\\intergenic regions\\phage gbk'\n",
    "                             + '/' + '287.19287.gbk', 'genbank'): \n",
    "    a = seq_record.seq\n",
    "    print(a[286\n",
    "           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed822c7-b240-4342-a904-81a415afb1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now make an array for every startstop combination\n",
    "array_dict = {}\n",
    "for ii in range(big_intergenic_df.shape[0]): \n",
    "    start = big_intergenic_df.loc[ii, 'gene start']\n",
    "    stop = big_intergenic_df.loc[ii, 'gene stop']\n",
    "    array_dict[ii] = np.arange(start, stop, 1)\n",
    "#array_dict.keys()\n",
    "\n",
    "big_intergenic_df.loc[:, 'start stop array'] = array_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99fe4ee-5a55-4b1e-903c-2d607f08d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {'gene start': [], 'gene stop': []}\n",
    "for seq_record in SeqIO.parse(phage_gbks_filepath + '/' + '287.19293.gbk', 'genbank'): \n",
    "    for seq_feature in seq_record.features:\n",
    "        if seq_feature.type == 'CDS': \n",
    "            start = seq_feature.location.start\n",
    "            stop = seq_feature.location.end\n",
    "            dictionary['gene start'].append(int(start))\n",
    "            dictionary['gene stop'].append(int(stop))\n",
    "intergenic_df = pd.DataFrame(dictionary)\n",
    "intergenic_df.loc[:, 'ID'] = [phage_gbk_filename[:-4]]*intergenic_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642725a3-3e7c-4d8c-99b3-5c9280ff7a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = os.listdir(r'C:\\Users\\Halewijn\\OneDrive\\Documenten\\third year\\BEP\\thesis\\mutational analysis\\intergenic regions\\saved_intergenic_df')\n",
    "intergenic_regions_csvs = []\n",
    "for csv_file in csv_files: \n",
    "    if csv_file.endswith('_region.csv'): \n",
    "        intergenic_regions_csvs = intergenic_regions_csvs + [csv_file]\n",
    "        \n",
    "#get the ID name out\n",
    "csv_file_df = pd.DataFrame(intergenic_regions_csvs).rename({0: 'filename'}, axis = 1)\n",
    "ID_array = list(csv_file_df.loc[:, 'filename'].str.extract('(.*?)(?<= )').replace(np.NaN, ' ').loc[:, 0])\n",
    "ID_array = [ x[:-1] for x in ID_array ]\n",
    "csv_file_df.loc[:, 'ID'] = ID_array\n",
    "indexes_remaning = csv_file_df[csv_file_df.loc[:, 'ID'] == ''].index\n",
    "ID_array_remaining = list(csv_file_df.iloc[indexes_remaning].loc[:, 'filename'].str.extract('(.*?)(?=intergenic)').loc[:,0])\n",
    "csv_file_df.loc[indexes_remaning, 'ID'] = ID_array_remaining\n",
    "\n",
    "# #also do the import the ID dataset, so that we can merge on phage name\n",
    "# ID_df = pd.read_csv(r'C:\\Users\\Halewijn\\OneDrive\\Documenten\\third year\\BEP\\thesis\\anti defence gene bioinformatics\\ID' + '/' + 'ID.csv')\n",
    "# ID_df = ID_df.dropna()\n",
    "# ID_df.columns = ['Job', 'Owner', \"ID\", \"phage\", \"Num contigs\", \"Size (bp)\"]\n",
    "# ID_df = ID_df.reindex(['ID', 'Size (bp)', 'phage'], axis =1)\n",
    "# ID_df.loc[:, 'phage'] = list(ID_df.loc[:, 'phage'].str.extract('(?<=FB)(.*)').loc[:, 0])\n",
    "# ID_df.loc[:, 'ID'] = ID_df.loc[:, 'ID'].astype('str')\n",
    "\n",
    "# #merge the ID and the csv dataset\n",
    "# csv_file_df = pd.merge(csv_file_df, ID_df).reset_index(drop = True)\n",
    "\n",
    "\n",
    "# #now that everything is ready, we can start importing the intergenic dataset, we need to loop over all the filenames in our csv_file_df\n",
    "# input_filepath = r'C:\\Users\\Halewijn\\OneDrive\\Documenten\\third year\\BEP\\thesis\\mutational analysis\\intergenic regions\\saved_intergenic_df'\n",
    "# big_intergenic_df = []\n",
    "# for ii in range(csv_file_df.shape[0]):\n",
    "#     input_filename = csv_file_df.loc[ii, 'filename']\n",
    "#     intergenic_df = pd.read_csv(input_filepath + '/' + input_filename).rename({'unnamed: 0': 'POS'}, axis = 1)\n",
    "#     #phage_name = csv_file_df.loc[ii, 'phage']\n",
    "#     #print(phage_name)\n",
    "#     #intergenic_df.loc[:, 'phage'] = [phage_name]*intergenic_df.shape[0]\n",
    "#     big_intergenic_df = big_intergenic_df + [intergenic_df]\n",
    "    \n",
    "# big_intergenic_df = pd.concat(big_intergenic_df).rename({'Unnamed: 0': 'POS'}, axis = 1)\n",
    "# #big_intergenic_df.loc[:, 'ALT evidence'] = big_intergenic_df.loc[:, 'EVIDENCE'].str.extract('(?<=:)(.*)(?= )').loc[0]\n",
    "\n",
    "# #now merge \n",
    "# #intergenic_big_big_df = pd.merge(big_big_df, big_intergenic_df, left_on = ['POS', 'reference'], right_on = ['POS', 'reference'])\n",
    "# ref_big_big_df = pd.merge(big_big_df, morphology_df, left_on = 'reference', right_on='phage').rename({'morphology': 'morphology reference'}, axis = 1)\n",
    "# read_ref_big_big_df = pd.merge(ref_big_big_df, morphology_df, left_on = 'reads', right_on='phage').rename({'morphology': 'morphology read'}, axis = 1)\n",
    "\n",
    "# #big\n",
    "# #intergenic_big_big_df.to_csv('big_snp_df.csv', index = False)\n",
    "# #intergenic_big_big_df.to_csv('snippy_df.csv', index = False)\n",
    "# read_ref_big_big_df.to_csv('snippy_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce93607-e970-40e7-8217-73525c4076d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "intergenic_regions_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc78dd4-cfbb-468d-af13-3d495523e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_intergenic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfd840f-cce9-46e1-8c56-6e9b5bc5b95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "intergenic_big_big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53050138-9e23-41e6-b448-954d5ae5c43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "phage = 'Pa12'\n",
    "type_ = 'snp'\n",
    "inter_or_intra = 'intra'\n",
    "morphology = 'Myoviridae'\n",
    "intra_df_snp = intergenic_big_big_df[(intergenic_big_big_df.loc[:, 'reference'] == phage) & (intergenic_big_big_df.loc[:, 'TYPE'] == type_)\n",
    "                     & (intergenic_big_big_df.loc[:, 'inter or intra'] == inter_or_intra)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6e9a44-4a94-4428-927f-93f5e5b78bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence_data = intra_df_snp.loc[:, 'ALT evidence']\n",
    "log_evidence_data= np.log10(evidence_data)\n",
    "minimum = log_evidence_data.min()\n",
    "maximum = log_evidence_data.max()\n",
    "print(minimum)\n",
    "print(maximum)\n",
    "#x_tick_array = np.arange(minimum, maximum, 100)\n",
    "sns.displot(log_evidence_data)\n",
    "#plt.xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc3c5f3-81c1-40a2-9ff1-e93a5fa034d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "phage = 'Pa10'\n",
    "type_ = 'snp'\n",
    "inter_or_intra = 'intra'\n",
    "morphology = 'Myoviridae'\n",
    "intra_df_snp = intergenic_big_big_df[(intergenic_big_big_df.loc[:, 'morphology'] == morphology) & (intergenic_big_big_df.loc[:, 'TYPE'] == type_)\n",
    "                     & (intergenic_big_big_df.loc[:, 'inter or intra'] == inter_or_intra)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9899e4f0-ae13-457b-9f0f-e5abfc85caa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence_data = intra_df_snp.loc[:, 'ALT evidence']\n",
    "log_evidence_data= np.log10(evidence_data)\n",
    "minimum = log_evidence_data.min()\n",
    "maximum = log_evidence_data.max()\n",
    "print(minimum)\n",
    "print(maximum)\n",
    "#x_tick_array = np.arange(minimum, maximum, 100)\n",
    "sns.displot(log_evidence_data)\n",
    "#plt.xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f1895e-4fe8-4ecb-9789-70d13b5a2816",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_intra_df_snp = intra_df_snp\n",
    "snp_positions = list(filled_intra_df_snp.loc[:, 'POS'])\n",
    "unfilled_positions = list(set(np.arange(0,max(snp_positions),1)).symmetric_difference(set(snp_positions)))\n",
    "\n",
    "dictionary = {}\n",
    "# for ii in range(len(unfilled_positions)): \n",
    "\n",
    "number_of_unfilled_positions = len(unfilled_positions)\n",
    "\n",
    "#CHROM_array\n",
    "CHROM_array = [filled_intra_df_snp.iloc[0, 0]]*number_of_unfilled_positions\n",
    "#POS_array\n",
    "POS_array = []\n",
    "for ii in range(len(unfilled_positions)): \n",
    "    POS_array = POS_array + [unfilled_positions[ii]]\n",
    "#TYPE\n",
    "TYPE_array = ['no snp']*number_of_unfilled_positions\n",
    "#REF \n",
    "REF_array = [np.NaN]*number_of_unfilled_positions\n",
    "#ALS \n",
    "ALT_array = [np.NaN]*number_of_unfilled_positions\n",
    "#EVIDENCE\n",
    "EVIDENCE_array = [np.NaN]*number_of_unfilled_positions\n",
    "#family\n",
    "family_array = [np.NaN]*number_of_unfilled_positions\n",
    "#inter or intra\n",
    "inter_or_intra_array = [np.NaN]*number_of_unfilled_positions\n",
    "#reference\n",
    "reference_array = [np.NaN]*number_of_unfilled_positions\n",
    "#reads\n",
    "reads_array = [np.NaN]*number_of_unfilled_positions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dictionary['CHROM'] = CHROM_array\n",
    "dictionary[\"POS\"] = POS_array\n",
    "dictionary['TYPE'] = TYPE_array\n",
    "dictionary['REF'] = REF_array\n",
    "dictionary['ALT'] = ALT_array\n",
    "dictionary['EVIDENCE'] = EVIDENCE_array\n",
    "dictionary['inter or intra'] = inter_or_intra_array\n",
    "dictionary['reference'] = reference_array\n",
    "dictionary['reads'] = reads_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dcfc82-5cca-4c94-8a58-6e076b941a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 50\n",
    "max_frame = 5\n",
    "filled_intra_df_snp = filled_intra_df_snp.append(pd.DataFrame(dictionary)).sort_values('POS')\n",
    "filled_intra_df_snp.loc[:, 'snp'] = list(filled_intra_df_snp.loc[:, 'TYPE'] == 'snp')\n",
    "filled_intra_df_snp.loc[:, 'moving sum of snps'] =list(filled_intra_df_snp.loc[:, 'snp'].rolling(frame).sum())\n",
    "filled_intra_df_snp.loc[:, 'moving max of moving sum of snps'] =list(filled_intra_df_snp.loc[:, 'moving sum of snps'].rolling(max_frame).max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2e767b-9b93-482c-baab-d24a344477f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_intra_df_snp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512959b2-1872-46a7-b9ad-288525a06028",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = filled_intra_df_snp, x = 'POS', y = 'inter or intra')\n",
    "plt.xlim(0,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4572d0e3-d969-45bb-bb5d-756d57f5f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = filled_intra_df_snp, x = 'POS', y = 'moving max of moving sum of snps', hue = 'intergenic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e4669d-f548-4dcc-86eb-2cf11ed7f8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = filled_intra_df_snp[filled_intra_df_snp.loc[:, 'moving sum of snps'] > 12].reset_index()\n",
    "sns.histplot(data = hist_df, x = 'POS', bins=200, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecda611b-36ab-4310-9453-4552638d5d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_big_df[(big_big_df.loc[:, 'inter or intra'] == 'intra') & (big_big_df.loc[:, 'family'] == 2)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c587321-8347-4424-8b66-cc180ecd9ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_big_df.loc[:, 'family'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a68fa2-c6a1-48c7-bd59-68ceb6b830c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
